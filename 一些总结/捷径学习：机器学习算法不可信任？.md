以下内容来自: https://thegradient.pub/shortcuts-neural-networks-love-to-cheat/

捷径学习：机器学习算法不可信任？

分类器没有学习如何“理解”肺炎，而是选择了最简单的解决方案，仅查看标记类型。

生物学学习者也遇到非常相似的失败模式。

在算法级别上，通常会默认一个假设，即类人的表现意味着类人的策略（或算法）。这种“相同的策略假设”同样存在于深度学习：即使DNN单元与生物神经元不同，但如果DNN成功识别出物体，那么似乎可以很自然地认为它们是像人类一样使用通过物体的形状来识别物体。因此，我们需要区分实验对象在一个数据集的性能表现与获取能力之间的联系，在将“物体识别”或“语言理解”等高级能力赋予机器之前，我们要非常谨慎，因为通常有一个更简单的解释: 可以归因于捷径学习时，切勿使用高级能力进行解释。

捷径学习是当前ML模型与人类智能之间最具标志性的差异。但具有讽刺意味的是，正是这种对“作弊”的偏爱，使神经网络看起来几乎和人类又相像了几分：谁还没有过在考试前偷懒背材料，而不是花时间去真正理解的经历？谁从来没有试图在一项法规中寻找漏洞，而不是坚持法律的精神？最后，神经网络也许和（懒惰的）人类并没有什么不同